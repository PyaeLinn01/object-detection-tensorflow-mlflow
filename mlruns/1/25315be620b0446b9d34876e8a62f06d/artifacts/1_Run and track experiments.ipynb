{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2008fa7",
   "metadata": {},
   "source": [
    "# 1. Running and tracking machine learning experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be61d6",
   "metadata": {},
   "source": [
    "## 1.0. The data we use: Palmer Pinguins\n",
    "\n",
    "Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. It provides a great dataset for data exploration & visualization, as an alternative to iris.\n",
    "\n",
    "We will use this dataset in classification setting to predict the penguins’ species from anatomical information.\n",
    "\n",
    "Each penguin is from one of the three following species: Adelie, Gentoo, and Chinstrap.\n",
    "\n",
    "![palmer penguins](../resources/palmer_penguins.png \"Palmer Penguins\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b6ce1",
   "metadata": {},
   "source": [
    "This problem is a classification problem since the target is categorical. We will use features based on penguins’ culmen measurement.\n",
    "\n",
    "![Culmen features](../resources/culmen_depth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dee973",
   "metadata": {},
   "source": [
    "## 1.1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5501ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Culmen Depth (mm)</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>40.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>45.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>39.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>45.1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>Gentoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>Adelie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Culmen Length (mm)  Culmen Depth (mm) Species\n",
       "142                40.7               17.0  Adelie\n",
       "230                45.2               16.4  Gentoo\n",
       "138                39.7               17.9  Adelie\n",
       "172                45.1               14.5  Gentoo\n",
       "5                  38.9               17.8  Adelie"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33dd0e",
   "metadata": {},
   "source": [
    "## 1.2. The modelling: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9daa4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f76a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3780fd",
   "metadata": {},
   "source": [
    "## 1.3. MLflow Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cded149",
   "metadata": {},
   "source": [
    "### Tracking stores\n",
    "\n",
    "MLflow supports two types of backend stores: file store and database-backed store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`.\n",
    "- Database encoded as +://:<password>@:/. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://, a Databricks CLI profile.)\n",
    "\n",
    "### Artifact stores\n",
    "Where you store models, plots and other stuff.\n",
    "\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98893984",
   "metadata": {},
   "source": [
    "## 1.4. Setup and configure the tracking server"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "150febdf",
   "metadata": {},
   "source": [
    "We want to use a database as a tracking store and a local directory as artifact store.\n",
    "Using a database is required for later steps in the tutorial, like managing deployments. In this case, artifacts are stored under the local ./mlruns directory, and MLflow entities are inserted in a SQLite database file mlruns.db.\n",
    "\n",
    "\n",
    "![tracking setup](../resources/tracking_setup.png)\n",
    "\n",
    "\n",
    "Run to start the tracking server:\n",
    "\n",
    "```mlflow server --backend-store-uri sqlite:///mflow.db --default-artifact-root mlruns/ --host 0.0.0.0 --port 5001```\n",
    "\n",
    "in a terminal. Make sure you run it inside the virtual environment! Put `pipenv run` in front of it.\n",
    "\n",
    "Now you should be able to see the Tracking UI in a browser at `http://0.0.0.0:5001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a947eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "447b5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_server_uri = \"http://0.0.0.0:5001\"   # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36fa3afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://0.0.0.0:5001'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930ea21",
   "metadata": {},
   "source": [
    "### Create a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21e087de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_ALREADY_EXISTS: Experiment(name=penguin_classification) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(sqlite3.IntegrityError) UNIQUE constraint failed: experiments.name\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (?, ?, ?, ?, ?)]\n[parameters: ('penguin_classification', '', 'active', 1681034167511, 1681034167511)]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m exp_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpenguin_classification\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m mlflow\u001b[39m.\u001b[39;49mcreate_experiment(exp_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.10/site-packages/mlflow/tracking/fluent.py:1221\u001b[0m, in \u001b[0;36mcreate_experiment\u001b[0;34m(name, artifact_location, tags)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_experiment\u001b[39m(\n\u001b[1;32m   1177\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   1178\u001b[0m     artifact_location: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1179\u001b[0m     tags: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1180\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   1181\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m \u001b[39m    Create an experiment.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[39m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1221\u001b[0m     \u001b[39mreturn\u001b[39;00m MlflowClient()\u001b[39m.\u001b[39;49mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.10/site-packages/mlflow/tracking/client.py:506\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_experiment\u001b[39m(\n\u001b[1;32m    459\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    460\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    461\u001b[0m     artifact_location: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    462\u001b[0m     tags: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    463\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    464\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[1;32m    466\u001b[0m \u001b[39m    :param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39m        Lifecycle_stage: active\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:234\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[39m:param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m:return: Integer ID of the created experiment.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    232\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mcreate_experiment(\n\u001b[1;32m    235\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    236\u001b[0m     artifact_location\u001b[39m=\u001b[39;49martifact_location,\n\u001b[1;32m    237\u001b[0m     tags\u001b[39m=\u001b[39;49m[ExperimentTag(key, value) \u001b[39mfor\u001b[39;49;00m (key, value) \u001b[39min\u001b[39;49;00m tags\u001b[39m.\u001b[39;49mitems()] \u001b[39mif\u001b[39;49;00m tags \u001b[39melse\u001b[39;49;00m [],\n\u001b[1;32m    238\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:95\u001b[0m, in \u001b[0;36mRestStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m     91\u001b[0m tag_protos \u001b[39m=\u001b[39m [tag\u001b[39m.\u001b[39mto_proto() \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mif\u001b[39;00m tags \u001b[39melse\u001b[39;00m []\n\u001b[1;32m     92\u001b[0m req_body \u001b[39m=\u001b[39m message_to_json(\n\u001b[1;32m     93\u001b[0m     CreateExperiment(name\u001b[39m=\u001b[39mname, artifact_location\u001b[39m=\u001b[39martifact_location, tags\u001b[39m=\u001b[39mtag_protos)\n\u001b[1;32m     94\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(CreateExperiment, req_body)\n\u001b[1;32m     96\u001b[0m \u001b[39mreturn\u001b[39;00m response_proto\u001b[39m.\u001b[39mexperiment_id\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:56\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     54\u001b[0m endpoint, method \u001b[39m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     55\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[0;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:281\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     response \u001b[39m=\u001b[39m http_request(\n\u001b[1;32m    279\u001b[0m         host_creds\u001b[39m=\u001b[39mhost_creds, endpoint\u001b[39m=\u001b[39mendpoint, method\u001b[39m=\u001b[39mmethod, json\u001b[39m=\u001b[39mjson_body\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    282\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    283\u001b[0m parse_dict(js_dict\u001b[39m=\u001b[39mjs_dict, message\u001b[39m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlops/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:207\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mif\u001b[39;00m _can_parse_as_json_object(response\u001b[39m.\u001b[39mtext):\n\u001b[0;32m--> 207\u001b[0m         \u001b[39mraise\u001b[39;00m RestException(json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext))\n\u001b[1;32m    208\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m         base_msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAPI request to endpoint \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m failed with error code \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m != 200\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    210\u001b[0m             endpoint,\n\u001b[1;32m    211\u001b[0m             response\u001b[39m.\u001b[39mstatus_code,\n\u001b[1;32m    212\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_ALREADY_EXISTS: Experiment(name=penguin_classification) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(sqlite3.IntegrityError) UNIQUE constraint failed: experiments.name\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (?, ?, ?, ?, ?)]\n[parameters: ('penguin_classification', '', 'active', 1681034167511, 1681034167511)]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "exp_name = \"penguin_classification\"\n",
    "mlflow.create_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc6a11",
   "metadata": {},
   "source": [
    "## 1.5. Add tracking code to the machine learning experiment above\n",
    "\n",
    "Basic things to track:\n",
    "- Parameters: Key-value input parameters: `mlflow.log_param, mlflow.log_params`\n",
    "- Metrics: Key-value metrics, where the value is numeric (can be updated over the run): `mlflow.log_metric, mlflow.log_metrics`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765bc20",
   "metadata": {},
   "source": [
    "Recall the following code from above:\n",
    "\n",
    "```python\n",
    "# Load dataset\n",
    "culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "target_column = \"Species\"\n",
    "\n",
    "data_path = \"../data/penguins_classification.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Prepare a train-test-split\n",
    "data, target = data[culmen_columns], data[target_column]\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)\n",
    "\n",
    "# Initialize and fit a classifier\n",
    "tree = DecisionTreeClassifier(max_depth=3, max_leaf_nodes=4)\n",
    "tree.fit(data_train, target_train)\n",
    "\n",
    "# Calculate test scores\n",
    "test_score = tree.score(data_test, target_test)\n",
    "print(f\"Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "```\n",
    "\n",
    "\n",
    "Now we add the required code to track the experiment with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fedeecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run bed3e0cf8f3f4a189f46c11c7690931d\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a6d30",
   "metadata": {},
   "source": [
    "Have a look at the tracking UI to see how it played out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28e17d",
   "metadata": {},
   "source": [
    "## 1.6. Exercise: track some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a513541",
   "metadata": {},
   "source": [
    "What else could we want to track?\n",
    "\n",
    "Examples:  \n",
    "- Code Version: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- Start & End Time: Start and end time of the run\n",
    "- Source: what code run?\n",
    "- Plots.\n",
    "- Properties of the input data\n",
    "- Model artifacts\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac48edd",
   "metadata": {},
   "source": [
    "### Exercises: \n",
    "- Track the properties of the input data as parameters. (Hint: `data.shape[0]` gives the number of samples in a dataframe)\n",
    "- Track the notebook 'source code'. (Hint: `mlflow.log_artifact()` takes a path and copies the file to the artifact store.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "\n",
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a39f8f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run c255925d4e2348f09c3f0960f8a428f2\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=3, max_leaf_nodes4\n",
      "Result: Accuracy of the DecisionTreeClassifier: 96.5%\n"
     ]
    }
   ],
   "source": [
    "# POSSIBLE SOLUTION:\n",
    "\n",
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])  # <-- ADDED: track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 3\n",
    "    max_leaf_nodes = 4\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")  # <-- ADDED: track the source code of the notebook\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548fff0",
   "metadata": {},
   "source": [
    "## 1.7. Log the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84310",
   "metadata": {},
   "source": [
    "We want to store the model artifacts to reuse it for deployment or later experimentation.\n",
    "Since we used a scikit-learn model here, we can use the build-in module to store the model in sklearn format. \n",
    "\n",
    "```mlflow.sklearn.log_model(tree, \"model\")```\n",
    "\n",
    "There are buildin modules for all kind of types of models, as well as the possibility to specify a custom format. Even autologging is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ca2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run 25bfdd52da964623bbe7590679a266a9\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=10, max_leaf_nodes15\n",
      "Result: Accuracy of the DecisionTreeClassifier: 100.0%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)  # <-- set the experiment we want to track to\n",
    "with mlflow.start_run() as run:         # <-- start a run of the experiment\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])  # <-- track the number of samples in the dataset\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 10\n",
    "    max_leaf_nodes = 15\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(            # <-- Track parameters\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)   # <-- Track metrics\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\")  # <-- Log the model\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")  # <-- track the source code of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d31206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice: Run the experiment (in the above cell) with different model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcaf369",
   "metadata": {},
   "source": [
    "## 1.8. Compare models in the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461ec0c",
   "metadata": {},
   "source": [
    "## 1.9. Optional: Add a signature to the model\n",
    "\n",
    "Define what the model expects and enforce later in deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd07df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"Culmen Length (mm)\"),\n",
    "  ColSpec(\"double\", \"Culmen Depth (mm)\"),\n",
    "])\n",
    "output_schema = Schema([ColSpec(\"string\", \"Species\")])\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35afcf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started run b3b011aae1b94488ab4b80bf3f439fc7\n",
      "Load dataset...\n",
      "Prepare a train-test-split...\n",
      "Initialize and fit a DecisionTreeClassifier with max_depth=10, max_leaf_nodes15\n",
      "Result: Accuracy of the DecisionTreeClassifier: 100.0%\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(exp_name)\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Started run {run.info.run_id}\")\n",
    "    # Load dataset\n",
    "    print(\"Load dataset...\")\n",
    "    culmen_columns = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\n",
    "    target_column = \"Species\"\n",
    "\n",
    "    data_path = \"../data/penguins_classification.csv\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    mlflow.log_param(\"num_samples\", data.shape[0])\n",
    "\n",
    "    # Prepare a train-test-split\n",
    "    print(\"Prepare a train-test-split...\")\n",
    "    data, target = data[culmen_columns], data[target_column]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(\n",
    "        data, target, random_state=0)\n",
    "\n",
    "    # Initialize and fit a classifier\n",
    "    max_depth = 10\n",
    "    max_leaf_nodes = 15\n",
    "    print(f\"Initialize and fit a DecisionTreeClassifier with max_depth={max_depth}, max_leaf_nodes{max_leaf_nodes}\")\n",
    "    \n",
    "    mlflow.log_params(\n",
    "        {\"max_depth\": max_depth, \n",
    "         \"max_leaf_nodes\": max_leaf_nodes}\n",
    "    )\n",
    "    tree = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        max_leaf_nodes=max_leaf_nodes\n",
    "    )\n",
    "    tree.fit(data_train, target_train)\n",
    "\n",
    "    # Calculate test scores\n",
    "    test_score = tree.score(data_test, target_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_score)\n",
    "    print(f\"Result: Accuracy of the DecisionTreeClassifier: {test_score:.1%}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(tree, \"model\", signature=signature)  # <-- Now log the model with a signature\n",
    "    mlflow.log_artifact(\"1_Run and track experiments.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b7642",
   "metadata": {},
   "source": [
    "## 1.10. Use the model to predict locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550aa26",
   "metadata": {},
   "source": [
    "Now we pick a model, retrieve it and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70f86ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adelie', 'Chinstrap', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Gentoo', 'Chinstrap', 'Adelie', 'Chinstrap', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Chinstrap', 'Gentoo', 'Chinstrap', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Chinstrap', 'Gentoo', 'Gentoo', 'Chinstrap', 'Adelie', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Chinstrap', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Gentoo'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = 'runs:/b3b011aae1b94488ab4b80bf3f439fc7/model'\n",
    "\n",
    "# Load model as a Sklearn Model.\n",
    "loaded_model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "loaded_model.predict(pd.DataFrame(data_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
