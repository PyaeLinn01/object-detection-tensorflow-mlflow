{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14b9d4d3",
   "metadata": {},
   "source": [
    "# 2. How to deploy from MLflow with python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da14fd4a",
   "metadata": {},
   "source": [
    "## 2.1 MLflow Models\n",
    "\n",
    "An MLflow Model is a standard format for packaging machine learning models that can be used in a variety of downstream tools - for example, real-time serving through a REST API or batch inference on Apache Spark. The format defines a convention that lets you save a model in different “flavors” that can be understood by different downstream tools.\n",
    "\n",
    "All of the flavors that a particular model supports are defined in its MLmodel file in YAML format. For example, mlflow.sklearn outputs models as follows:\n",
    "\n",
    "```\n",
    "# Directory written by mlflow.sklearn.save_model(tree, \"model\")\n",
    "model/\n",
    "├── MLmodel\n",
    "├── model.pkl\n",
    "├── conda.yaml\n",
    "└── requirements.txt\n",
    "```\n",
    "\n",
    "For environment recreation, we automatically log conda.yaml and requirements.txt files whenever a model is logged. These files can then be used to reinstall dependencies using either conda or pip. And its MLmodel file describes two flavors:\n",
    "\n",
    "```yaml\n",
    "time_created: 2018-05-25T17:28:53.35\n",
    "\n",
    "flavors:\n",
    "  sklearn:\n",
    "    sklearn_version: 0.19.1\n",
    "    pickled_model: model.pkl\n",
    "  python_function:\n",
    "    loader_module: mlflow.sklearn\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30cbf0d0",
   "metadata": {},
   "source": [
    "This model can then be used with any tool that supports either the sklearn or python_function model flavor. For example, the mlflow models serve command can serve a model with the python_function flavor:\n",
    "\n",
    "```bash\n",
    "mlflow models serve -m model\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f577144e",
   "metadata": {},
   "source": [
    "## 2.2 The MLflow Model Registry\n",
    "\n",
    "The MLflow Model Registry component is a centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of an MLflow Model. It provides model lineage (which MLflow experiment and run produced the model), model versioning, stage transitions (for example from staging to production), and annotations.\n",
    "\n",
    "- **Model**: A MLflow Model is created from an experiment or run that is logged with one of the model flavor’s mlflow.\\<model_flavor\\>.log_model() methods. Once logged, this model can then be registered with the Model Registry.\n",
    "\n",
    "- **Registered Model**: A MLflow Model can be registered with the Model Registry. A registered model has a unique name, contains versions, associated transitional stages, model lineage, and other metadata.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd8c1a65",
   "metadata": {},
   "source": [
    "## 2.3. Register a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c906e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "remote_server_uri = \"http://0.0.0.0:5001\"   # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f90a8504",
   "metadata": {},
   "source": [
    "First we need to create registred model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94949859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'penguin' already exists in registry.\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import RestException\n",
    "\n",
    "model_name = \"penguin\"\n",
    "\n",
    "client = MlflowClient()\n",
    "try:\n",
    "    registered_model = client.create_registered_model(model_name)\n",
    "    print(registered_model)\n",
    "except RestException:\n",
    "    print(f\"Model '{model_name}' already exists in registry.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "378d2b26",
   "metadata": {},
   "source": [
    "Now we can register experiment runs to that model. Pick a run ID from your tracking log and add it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bf1e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'penguin' already exists. Creating a new version of this model...\n",
      "2025/05/22 19:25:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: penguin, version 4\n",
      "Created version '4' of model 'penguin'.\n"
     ]
    }
   ],
   "source": [
    "run_id = \"0c2a356eecc141eb9ed000728ef2182c\"\n",
    "model_name = \"penguin\"\n",
    "result = mlflow.register_model(\n",
    "    f\"runs:/{run_id}/model\",\n",
    "    f\"{model_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bad46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ModelVersion: aliases=[], creation_timestamp=1747918519211, current_stage='None', description='', last_updated_timestamp=1747918519211, name='penguin', run_id='0c2a356eecc141eb9ed000728ef2182c', run_link='', source='mlflow-artifacts:/181050822057161957/0c2a356eecc141eb9ed000728ef2182c/artifacts/model', status='READY', status_message=None, tags={}, user_id='', version='4'>\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a7d3a28",
   "metadata": {},
   "source": [
    "## 2.4. Serve a Model from the registry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea195735",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Set environment variable for the tracking URL where the Model Registry resides\n",
    "# Serve the production model from the model registry\n",
    "MLFLOW_TRACKING_URI=http://localhost:5001 mlflow models serve --no-conda -m \"models:/penguin/4\" -p 4242\n",
    "```\n",
    "(This serves version 1 of the model)\n",
    "\n",
    "Save by stage:\n",
    "\n",
    "```bash\n",
    "MLFLOW_TRACKING_URI=http://localhost:5001 mlflow models serve --no-conda -m \"models:/penguins_clf_test_part_4/Production\" -p 4242\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d07d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4ee1894",
   "metadata": {},
   "source": [
    "Query the model with cURL:\n",
    "```bash\n",
    "# record-oriented DataFrame input (fine for vector rows, loses ordering for JSON records)\n",
    "curl http://127.0.0.1:4242/invocations -H 'Content-Type: application/json; format=pandas-records' -d '[\n",
    "    {\"Culmen Length (mm)\": 1,\"Culmen Depth (mm)\": 3},\n",
    "    {\"Culmen Length (mm)\": 14,\"Culmen Depth (mm)\": 120}\n",
    "]'\n",
    "```\n",
    "\n",
    "Or we can call the API directly from python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7897545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "\n",
    "url = \"http://127.0.0.1:4242/invocations\"\n",
    "\n",
    "headers = CaseInsensitiveDict()\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "\n",
    "data = {\n",
    "    \"dataframe_split\": {\n",
    "         \"columns\": [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"],\n",
    "         \"data\": [[1.8,  14.7], [ 3.0,120.0 ]]\n",
    "    }\n",
    "}\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd7d9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"predictions\": [\"Adelie\", \"Adelie\"]}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1505f496",
   "metadata": {},
   "source": [
    "## 2.5. Other deployment targets\n",
    "\n",
    "- Sagemaker\n",
    "- AzureML\n",
    "- Kubernetes\n",
    "- ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7df36042",
   "metadata": {},
   "source": [
    "## 2.6. Transition a models stages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e905ed9",
   "metadata": {},
   "source": [
    "Over the course of the model’s lifecycle, a model evolves—from development to staging to production. You can transition a registered model to one of the stages: **Staging, Production or Archived.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4dca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393456a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d3/vskdykq51ls6y387np4y9flr0000gn/T/ipykernel_2543/2955111842.py:3: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1747915421748, current_stage='Production', description='', last_updated_timestamp=1747919359751, name='penguin', run_id='bc33c515123347fab91528a9a95dc764', run_link='', source='mlflow-artifacts:/181050822057161957/bc33c515123347fab91528a9a95dc764/artifacts/model', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
